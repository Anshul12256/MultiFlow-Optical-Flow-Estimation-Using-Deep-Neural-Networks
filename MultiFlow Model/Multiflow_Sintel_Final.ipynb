{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiflow_Sintel_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xZF_ZsARogO"
      },
      "source": [
        "# Use TensorFlow 2.1.0 for Code Development\n",
        "!pip install --upgrade tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMoX5mEtcBiU"
      },
      "source": [
        "# Import all libraries\n",
        "%tensorflow_version 2.x     #Use this command while using Google Colab else skip\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import uuid\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "import tensorflow as tf\n",
        "import matplotlib.colors as cl\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow_addons.optimizers import AdamW\n",
        "from tensorflow_addons.layers import CorrelationCost\n",
        "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, InputLayer, Concatenate, LeakyReLU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMmMWUGtR6_d"
      },
      "source": [
        "# Use this commands while using Google Colab else skip\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDDeXT45R7vt"
      },
      "source": [
        "# Use this commands while using Google Colab else skip\n",
        "!unzip -uq \"/content/gdrive/My Drive/Thesis/Sintel_Files/final.zip\" -d \"/final\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbxbZSVicIw6"
      },
      "source": [
        "# Reading .csv for input image frame triplets and ground-truth optical flow\n",
        "df= pd.read_csv('/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Dataframes/alley1_train.csv') # .csv for input and output sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA67TBRScrHR"
      },
      "source": [
        "# Displaying dataframe and its length\n",
        "print(df)\n",
        "print(\"Length of Dataframe is: \",len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxHsvEVNg3Uo"
      },
      "source": [
        "# Coverting dataframe column to list to pass it for mapping in tf.dataset\n",
        "img_1_list = df['img1'].tolist() \n",
        "img_2_list = df['img2'].tolist()\n",
        "img_3_list = df['img3'].tolist()\n",
        "flo_list = df['flow'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8uiy5yzjDpo"
      },
      "source": [
        "# Reading image frames from directory\n",
        "images_dir = \"/final/final/\"\n",
        "def load_image(img_1,img_2,img_3):\n",
        "    \n",
        "    img1 = tf.io.read_file(images_dir+img_1.decode(\"utf-8\"))\n",
        "    img1 = tf.image.decode_png(img1, channels=3)\n",
        "\n",
        "    img2 = tf.io.read_file(images_dir+img_2.decode(\"utf-8\"))\n",
        "    img2 = tf.image.decode_png(img2, channels=3)\n",
        "    \n",
        "    img3 = tf.io.read_file(images_dir+img_3.decode(\"utf-8\"))\n",
        "    img3 = tf.image.decode_png(img3, channels=3)\n",
        "    \n",
        "    return img1, img2, img3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFRsXZC9TCVO"
      },
      "source": [
        "# Use this commands while using Google Colab else skip\n",
        "!unzip -uq \"/content/gdrive/My Drive/Thesis/Sintel_Files/flow.zip\" -d \"/flow\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lop4dBsRklux"
      },
      "source": [
        "# Converting .flo to numpy array\n",
        "flow_dir='/flow/flow/'   \n",
        "def readFlow(name):\n",
        "    if name.endswith('.pfm') or name.endswith('.PFM'):\n",
        "        return readPFM(name)[0][:,:,0:2]\n",
        "\n",
        "    f = open(name, 'rb')\n",
        "\n",
        "    header = f.read(4)\n",
        "    if header.decode(\"utf-8\") != 'PIEH':\n",
        "        raise Exception('Flow file header does not contain PIEH')\n",
        "\n",
        "    width = np.fromfile(f, np.int32, 1).squeeze()\n",
        "    height = np.fromfile(f, np.int32, 1).squeeze()\n",
        "\n",
        "    flow = np.fromfile(f, np.float32, width * height * 2).reshape((height, width, 2))\n",
        "\n",
        "    return flow.astype(np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2mQ4f9Pc3-a"
      },
      "source": [
        "# Mapping functions to tf.dataset\n",
        "def map_function(img_1,img_2,img_3,flow):\n",
        "    \n",
        "    img1, img2, img3 = load_image(img_1,img_2,img_3)\n",
        "    flow = readFlow(flow_dir+flow.decode(\"utf-8\"))\n",
        "    # mapping function for images to dataset\n",
        "    return tf.dtypes.cast(img1, tf.float32), tf.dtypes.cast(img2, tf.float32), tf.dtypes.cast(img3, tf.float32) , tf.dtypes.cast(flow, tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVFd2A90fWli"
      },
      "source": [
        "batch_size = 4\n",
        "dataset = tf.data.Dataset.from_tensor_slices((img_1_list,img_2_list,img_3_list,flo_list))\n",
        "\n",
        "# Use map_function to load the numpy files in parallel\n",
        "dataset = dataset.map(lambda item1, item2, item3, item4: tf.numpy_function(\n",
        "          map_function, [item1, item2, item3, item4], [tf.float32, tf.float32, tf.float32,tf.float32]),num_parallel_calls = tf.data.experimental.AUTOTUNE)#,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "# Shuffle and batch\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(buffer_size=4)\n",
        "dataset = dataset.batch(batch_size)\n",
        "dataset = dataset.prefetch(buffer_size = tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOzH_2QdOyoq"
      },
      "source": [
        "#Display number of elements in tf.dataset\n",
        "num_elements = tf.data.experimental.cardinality(dataset).numpy()\n",
        "print(\"Number of elements in tf.data.Dataset is :\",num_elements)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkuv0m4raAaB"
      },
      "source": [
        "#Shape adjustment function required in the model\n",
        "def crop_like(input, target): \n",
        "    if input.shape[1:3] == target.shape[1:3]:\n",
        "        return input\n",
        "    else:\n",
        "        return input[:, :target.shape[1],:target.shape[2],:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W82O80r2N4mt"
      },
      "source": [
        "#MultiFlow Model\n",
        "class MultiFlow(tf.keras.Model):\n",
        "  # Layer declaration\n",
        "  def __init__(self):\n",
        "    super(MultiFlow, self).__init__()\n",
        "    self.i1= InputLayer(input_shape=(436,1024,3))\n",
        "    self.i2= InputLayer(input_shape=(436,1024,3))\n",
        "    self.i3= InputLayer(input_shape=(436,1024,3))\n",
        "\n",
        "    #Input path-1\n",
        "    self.conva_1= Conv2D(64,7,strides=2,padding='same') #Convolution layer\n",
        "    self.conva_1_act = LeakyReLU(alpha=0.1) # LeakyRelu function\n",
        "    self.conva_2= Conv2D(128,5,strides=2,padding='same')\n",
        "    self.conva_2_act = LeakyReLU(alpha=0.1)\n",
        "    self.conva_3= Conv2D(256,5,strides=2,padding='same')\n",
        "    self.conva_3_act = LeakyReLU(alpha=0.1)\n",
        "    \n",
        "    #Input path-2\n",
        "    self.convb_1= Conv2D(64,7,strides=2,padding='same')\n",
        "    self.convb_1_act =LeakyReLU(alpha=0.1)\n",
        "    self.convb_2= Conv2D(128,5,strides=2,padding='same')\n",
        "    self.convb_2_act =LeakyReLU(alpha=0.1)\n",
        "    self.convb_3= Conv2D(256,5,strides=2,padding='same')\n",
        "    self.convb_3_act =LeakyReLU(alpha=0.1)\n",
        "\n",
        "    #Input path-3\n",
        "    self.convc_1= Conv2D(64,7,strides=2,padding='same')\n",
        "    self.convc_1_act =LeakyReLU(alpha=0.1)\n",
        "    self.convc_2= Conv2D(128,5,strides=2,padding='same')\n",
        "    self.convc_2_act =LeakyReLU(alpha=0.1)\n",
        "    self.convc_3= Conv2D(256,5,strides=2,padding='same')\n",
        "    self.convc_3_act =LeakyReLU(alpha=0.1)\n",
        "\n",
        "    #Correalation layer\n",
        "    self.cc = CorrelationCost(1,20,1,2,20,data_format='channels_last')\n",
        "\n",
        "    self.cr_1_act= LeakyReLU(alpha=0.1) #LeakyRelu for correaltion volume CR1\n",
        "    self.conva_redir= Conv2D(32,1,strides=1) #Convolution redir for features for CR1\n",
        "    self.conva_redir_act =LeakyReLU(alpha=0.1)\n",
        "    self.vol_1= Concatenate(axis=3)\n",
        "\n",
        "    self.cr_2_act= LeakyReLU(alpha=0.1) #LeakyRelu for correaltion volume CR2\n",
        "    self.convb_redir= Conv2D(32,1,strides=1) #Convolution redir for features for CR2\n",
        "    self.convb_redir_act = LeakyReLU(alpha=0.1)\n",
        "    self.vol_2 = Concatenate(axis=3)\n",
        "\n",
        "    #Passing CR1 and CR2 through convolution layers\n",
        "    self.conv_v1= Conv2D(256,5,strides=1,padding='same')\n",
        "    self.conv_v1_act =LeakyReLU(alpha=0.1)\n",
        "    self.conv_v2= Conv2D(256,5,strides=1,padding='same')\n",
        "    self.conv_v2_act =LeakyReLU(alpha=0.1)\n",
        "\n",
        "    #Correlation between volumes             \n",
        "    self.cr_3_act= LeakyReLU(alpha=0.1) #LeakyRelu for correaltion volume CR3\n",
        "    self.conv_v1_redir= Conv2D(32,1,strides=1) #Convolution redir for features for CR3\n",
        "    self.conv_v1_redir_act =LeakyReLU(alpha=0.1)\n",
        "    self.vol_3= Concatenate(axis=3)\n",
        "\n",
        "    #Single convolution stream\n",
        "    self.conv3_1= Conv2D(256,3,strides=1,padding='same')\n",
        "    self.conv3_1_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv4= Conv2D(512,3,strides=2,padding='same')\n",
        "    self.conv4_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv4_1= Conv2D(512,3,strides=1,padding='same')\n",
        "    self.conv4_1_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv5= Conv2D(512,3,strides=2,padding='same')\n",
        "    self.conv5_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv5_1= Conv2D(512,3,strides=1,padding='same')\n",
        "    self.conv5_1_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv6= Conv2D(1024,3,strides=2,padding='same')\n",
        "    self.conv6_act= LeakyReLU(alpha=0.1)\n",
        "    self.conv6_1= Conv2D(1024,3,strides=1,padding='same')\n",
        "    self.conv6_1_act= LeakyReLU(alpha=0.1)\n",
        "\n",
        "    #Refinement network\n",
        "    self.pf6= Conv2D(2,3,strides=1,padding='same')  #Predicted flow\n",
        "    self.dc5= Conv2DTranspose(512,4,strides=2,padding='same')  #Transpose convolution\n",
        "    self.dc5_act= LeakyReLU(alpha=0.1)\n",
        "    self.up_6to5= Conv2DTranspose(2,4,strides=2,padding='same') #Upsampled flow\n",
        "    self.con_5= Concatenate(axis=3)  #Concating 3 streams conv-features,deconv,upsampled_flow\n",
        "\n",
        "    self.pf5= Conv2D(2,3,strides=1,padding='same')\n",
        "    self.dc4= Conv2DTranspose(256,4,strides=2,padding='same')\n",
        "    self.dc4_act= LeakyReLU(alpha=0.1)\n",
        "    self.up_5to4= Conv2DTranspose(2,4,strides=2,padding='same')\n",
        "    self.con_4= Concatenate(axis=3)\n",
        "\n",
        "    self.pf4= Conv2D(2,3,strides=1,padding='same')\n",
        "    self.dc3= Conv2DTranspose(128,4,strides=2,padding='same')\n",
        "    self.dc3_act= LeakyReLU(alpha=0.1)\n",
        "    self.up_4to3= Conv2DTranspose(2,4,strides=2,padding='same')\n",
        "    self.con_3= Concatenate(axis=3)\n",
        "\n",
        "    self.pf3= Conv2D(2,3,strides=1,padding='same')\n",
        "    self.dc2= Conv2DTranspose(128,4,strides=2,padding='same')\n",
        "    self.dc2_act= LeakyReLU(alpha=0.1)\n",
        "    self.up_3to2= Conv2DTranspose(2,4,strides=2,padding='same')\n",
        "    self.con_2=Concatenate(axis=3)\n",
        "\n",
        "    self.pf2= Conv2D(2,3,strides=1,padding='same')\n",
        "    self.dc1= Conv2DTranspose(64,4,strides=2,padding='same')\n",
        "    self.dc1_act= LeakyReLU(alpha=0.1) \n",
        "    self.up_2to1= Conv2DTranspose(2,4,strides=2,padding='same')\n",
        "    self.con_1=Concatenate(axis=3)\n",
        "\n",
        "    self.pf1= Conv2D(2,3,strides=1,padding='same')\n",
        "\n",
        "  #Layer Definition\n",
        "  def call(self, input1,input2,input3,training=False):\n",
        "    i_1=self.i1(input1)\n",
        "    cona1=self.conva_1(i_1)\n",
        "    cona1_act=self.conva_1_act(cona1)\n",
        "    cona2=self.conva_2(cona1_act)\n",
        "    cona2_act=self.conva_2_act(cona2)\n",
        "    cona3=self.conva_3(cona2_act)\n",
        "    cona3_act=self.conva_3_act(cona3)\n",
        "\n",
        "    i_2=self.i2(input2)\n",
        "    conb1=self.convb_1(i_2)\n",
        "    conb1_act=self.convb_1_act(conb1)\n",
        "    conb2=self.convb_2(conb1_act)\n",
        "    conb2_act=self.convb_2_act(conb2)\n",
        "    conb3=self.convb_3(conb2_act)\n",
        "    conb3_act=self.convb_3_act(conb3)\n",
        "    \n",
        "    i_3=self.i3(input3)\n",
        "    conc1=self.convc_1(i_3)\n",
        "    conc1_act=self.convc_1_act(conc1)\n",
        "    conc2=self.convc_2(conc1_act)\n",
        "    conc2_act=self.convc_2_act(conc2)\n",
        "    conc3=self.convc_3(conc2_act)\n",
        "    conc3_act=self.convc_3_act(conc3)\n",
        "\n",
        "    cc1=self.cc([cona3_act,conb3_act])\n",
        "    cc1_act=self.cr_1_act(cc1)\n",
        "    cona_r=self.conva_redir(cona3_act)\n",
        "    cona_r_act=self.conva_redir_act(cona_r)\n",
        "    v1=self.vol_1([cc1_act,cona_r_act])\n",
        "\n",
        "    cc2=self.cc([conb3_act,conc3_act])\n",
        "    cc2_act=self.cr_2_act(cc2)\n",
        "    conb_r=self.convb_redir(conb3_act)\n",
        "    conb_r_act=self.convb_redir_act(conb_r)\n",
        "    v2=self.vol_2([cc2_act,conb_r_act])\n",
        "    \n",
        "    con_v1=self.conv_v1(v1)\n",
        "    con_v1_act=self.conv_v1_act(con_v1)\n",
        "    con_v2=self.conv_v2(v2)\n",
        "    con_v2_act=self.conv_v2_act(con_v2)\n",
        "\n",
        "    cc3=self.cc([con_v1_act,con_v2_act])\n",
        "    cc3_act=self.cr_3_act(cc3)\n",
        "    con_v1_r=self.conv_v1_redir(con_v1_act)\n",
        "    con_v1_r_act=self.conv_v1_redir_act(con_v1_r)\n",
        "    v3=self.vol_3([cc3_act,con_v1_r_act])\n",
        "\n",
        "    con3_1=self.conv3_1(v3)\n",
        "    con3_1_act=self.conv3_1_act(con3_1)\n",
        "    con4=self.conv4(con3_1_act)\n",
        "    con4_act=self.conv4_act(con4)\n",
        "    con4_1=self.conv4_1(con4_act)\n",
        "    con4_1_act=self.conv4_1_act(con4_1)\n",
        "    con5=self.conv5(con4_1_act)\n",
        "    con5_act=self.conv5_act(con5)\n",
        "    con5_1=self.conv5_1(con5_act)\n",
        "    con5_1_act=self.conv5_1_act(con5_1)\n",
        "    con6=self.conv6(con5_1_act)\n",
        "    con6_act=self.conv6_act(con6)\n",
        "    con6_1=self.conv6_1(con6_act)\n",
        "    con6_1_act=self.conv6_1_act(con6_1)\n",
        "\n",
        "\n",
        "\n",
        "    pf_6=self.pf6(con6_1_act)\n",
        "    dc_5=self.dc5(con6_1_act)\n",
        "    dc_5_act=self.dc5_act(dc_5)\n",
        "    ups_6to5=self.up_6to5(pf_6)\n",
        "    concat5=self.con_5([con5_1_act,dc_5_act,ups_6to5])\n",
        "\n",
        "    pf_5=self.pf5(concat5)\n",
        "    dc_4=self.dc4(concat5)\n",
        "    dc_4_act=self.dc4_act(dc_4)\n",
        "    ups_5to4=self.up_5to4(pf_5)\n",
        "    concat4=self.con_4([con4_1_act,dc_4_act,ups_5to4])\n",
        "\n",
        "    pf_4=self.pf4(concat4)\n",
        "    dc_3=self.dc3(concat4)\n",
        "    dc_3_act=self.dc3_act(dc_3)\n",
        "    dc_3_crop=crop_like(dc_3_act,con3_1_act)\n",
        "    ups_4to3=self.up_4to3(pf_4)\n",
        "    ups_4to3_crop=crop_like(ups_4to3,con3_1_act)\n",
        "    concat3=self.con_3([con3_1_act,dc_3_crop,ups_4to3_crop])\n",
        "\n",
        "    pf_3=self.pf3(concat3)\n",
        "    dc_2=self.dc2(concat3)\n",
        "    dc_2_act=self.dc2_act(dc_2)\n",
        "    dc_2_crop=crop_like(dc_2_act,con_v1_act)\n",
        "    ups_3to2=self.up_3to2(pf_3)\n",
        "    ups_3to2_crop=crop_like(ups_3to2,con_v1_act)\n",
        "    concat2=self.con_2([con_v1_act,dc_2_crop,ups_3to2_crop])\n",
        "\n",
        "    pf_2=self.pf2(concat2)\n",
        "    dc_1=self.dc1(concat2)\n",
        "    dc_1_act=self.dc1_act(dc_1)\n",
        "    dc_1_crop=crop_like(dc_1_act,cona2_act)\n",
        "    ups_2to1=self.up_2to1(pf_2)\n",
        "    ups_2to1_crop=crop_like(ups_2to1,cona2_act)\n",
        "    concat1=self.con_1([cona2_act,dc_1_crop,ups_2to1_crop])\n",
        "\n",
        "    pf_1=self.pf1(concat1)\n",
        "    flow=tf.image.resize(pf_1,tf.stack([436,1024]),method='bilinear') #Bilinear upsampling\n",
        "    return  {'flow': flow ,'predict_flow6': pf_6, 'predict_flow5': pf_5, 'predict_flow4': pf_4, 'predict_flow3': pf_3, 'predict_flow2': pf_2, 'predict_flow1': pf_1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7myah8gcrD8"
      },
      "source": [
        "model=MultiFlow()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRPvfQI2RAaC"
      },
      "source": [
        "# AEPE\n",
        "def a_epe(labels, predictions):  \n",
        "    squared_difference = tf.square(tf.subtract(predictions, labels))\n",
        "    loss = tf.reduce_mean(squared_difference)\n",
        "    loss = tf.sqrt(loss)\n",
        "    loss = loss/len(df)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBNJnMJnFJc1"
      },
      "source": [
        "#Multiscale loss function\n",
        "def loss_function(real, pred):\n",
        "\n",
        "  pred6 = pred['predict_flow6']\n",
        "  size = [pred6.shape[1], pred6.shape[2]]\n",
        "  df6 = tf.image.resize(real, tf.stack(size))\n",
        "  epe6 = 0.32 * (a_epe(df6, pred6))\n",
        "\n",
        "  pred5=pred['predict_flow5']\n",
        "  size = [pred5.shape[1], pred5.shape[2]]\n",
        "  df5 = tf.image.resize(real, tf.stack(size))\n",
        "  epe5 = 0.32 * (a_epe(df5, pred5))\n",
        "\n",
        "  pred4=pred['predict_flow4']\n",
        "  size = [pred4.shape[1], pred4.shape[2]]\n",
        "  df4 = tf.image.resize(real, tf.stack(size))\n",
        "  epe4 = 0.32 * (a_epe(df4, pred4))\n",
        "\n",
        "  pred3=pred['predict_flow3']\n",
        "  size = [pred3.shape[1], pred3.shape[2]]\n",
        "  df3 = tf.image.resize(real, tf.stack(size))\n",
        "  epe3 = 0.32 * (a_epe(df3, pred3))\n",
        "\n",
        "  pred2=pred['predict_flow2']\n",
        "  size = [pred2.shape[1], pred2.shape[2]]\n",
        "  df2 = tf.image.resize(real, tf.stack(size))\n",
        "  epe2 = 0.32 * (a_epe(df2, pred2))\n",
        "\n",
        "  pred1=pred['predict_flow1']\n",
        "  size = [pred1.shape[1], pred1.shape[2]]\n",
        "  df1 = tf.image.resize(real, tf.stack(size))\n",
        "  epe1 = 0.64 * (a_epe(df1, pred1))\n",
        "\n",
        "  loss = tf.math.add_n([epe6,epe5,epe4,epe3,epe2,epe1])\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJe0FLXRF4X4"
      },
      "source": [
        "# Custom Adam optimizer adam with weight decay\n",
        "# Manually decrease the learning rate according to the learning stage\n",
        "optimizer= AdamW(weight_decay=0.0004, learning_rate=0.0001, beta_1=0.9, beta_2=0.999) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKwuPCpxFBkd"
      },
      "source": [
        "#Loading checkpoint weights\n",
        "checkpoint_path = \"/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Checkpoints_Sintel/Final_Alley_1\"\n",
        "ckpt = tf.train.Checkpoint(model=model, optimizer = optimizer)\n",
        "ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wwxgdz4IFB7g"
      },
      "source": [
        "start_epoch = 0\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    start_epoch = int(ckpt_manager.latest_checkpoint.split('-')[-1])\n",
        "print(\"Start Epoch is\",start_epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JbQQ2uFPGAt"
      },
      "source": [
        "#Train function\n",
        "def train_step(input1,input2,input3,flow):\n",
        "    loss = 0\n",
        "    i = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        predict = model(input1,input2,input3)\n",
        "        loss = loss_function(flow,predict)\n",
        "        \n",
        "    trainable_variables = model.trainable_variables\n",
        "\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXXd3dnCx9Q",
        "scrolled": false
      },
      "source": [
        "# Train Function\n",
        "EPOCHS =  # Set the number of Epochs to train\n",
        "loss_list =[]\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    start = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (img1,img2,img3,target)) in enumerate(dataset):\n",
        "        batch_loss= train_step(img1,img2,img3,target)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        if batch % 100 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "    loss_list.append(total_loss)\n",
        "    if epoch % 1 == 0:\n",
        "        print(\"Saving model\\n\")\n",
        "        ckpt_manager.save()\n",
        "\n",
        "    print ('Epoch {} Loss {:.6f}'.format(epoch + 1,total_loss))\n",
        "    print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdGp7oD4vfcf"
      },
      "source": [
        "# Plotting loss list\n",
        "plt.plot(loss_list)\n",
        "plt.imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV1EAhlAvfck"
      },
      "source": [
        "# Saving loss list\n",
        "numpy_loss_history = np.array(loss_list)\n",
        "np.savetxt(\"alley1.txt\", numpy_loss_history, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSSbsYa9Vpav"
      },
      "source": [
        "# Visualization and Flow evalution compuation\n",
        "def visualize_flow_train(flow,i):\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    plt.imsave(\"/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Final_Scenes_Results/Alley_1/Train/\"+str(i)+\".png\",img)\n",
        "    return None\n",
        "\n",
        "def visualize_flow_test(flow,i):\n",
        "    img = flow_to_image(flow)\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    plt.imsave(\"/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Final_Scenes_Results/Alley_1/Test/\"+str(i)+\".png\",img)\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def flow_error(tu, tv, u, v):\n",
        "    UNKNOWN_FLOW_THRESH = 1e7\n",
        "    \"\"\"\n",
        "    Calculate average end point error\n",
        "    :param tu: ground-truth horizontal flow map\n",
        "    :param tv: ground-truth vertical flow map\n",
        "    :param u:  estimated horizontal flow map\n",
        "    :param v:  estimated vertical flow map\n",
        "    :return: End point error of the estimated flow\n",
        "    \"\"\"\n",
        "    smallflow = 0.0\n",
        "    '''\n",
        "    stu = tu[bord+1:end-bord,bord+1:end-bord]\n",
        "    stv = tv[bord+1:end-bord,bord+1:end-bord]\n",
        "    su = u[bord+1:end-bord,bord+1:end-bord]\n",
        "    sv = v[bord+1:end-bord,bord+1:end-bord]\n",
        "    '''\n",
        "    stu = tu[:]\n",
        "    stv = tv[:]\n",
        "    su = u[:]\n",
        "    sv = v[:]\n",
        "\n",
        "    idxUnknow = (abs(stu) > UNKNOWN_FLOW_THRESH) | (abs(stv) > UNKNOWN_FLOW_THRESH)\n",
        "    stu[idxUnknow] = 0\n",
        "    stv[idxUnknow] = 0\n",
        "    su[idxUnknow] = 0\n",
        "    sv[idxUnknow] = 0\n",
        "\n",
        "    ind2 = [(np.absolute(stu) > smallflow) | (np.absolute(stv) > smallflow)]\n",
        "    index_su = su[ind2]\n",
        "    index_sv = sv[ind2]\n",
        "    an = 1.0 / np.sqrt(index_su ** 2 + index_sv ** 2 + 1)\n",
        "    un = index_su * an\n",
        "    vn = index_sv * an\n",
        "\n",
        "    index_stu = stu[ind2]\n",
        "    index_stv = stv[ind2]\n",
        "    tn = 1.0 / np.sqrt(index_stu ** 2 + index_stv ** 2 + 1)\n",
        "    tun = index_stu * tn\n",
        "    tvn = index_stv * tn\n",
        "\n",
        "    epe = np.sqrt((stu - su) ** 2 + (stv - sv) ** 2)\n",
        "    epe = epe[ind2]\n",
        "    mepe = np.mean(epe)\n",
        "    return mepe\n",
        "\n",
        "\n",
        "def flow_to_image(flow):\n",
        "    UNKNOWN_FLOW_THRESH = 1e7\n",
        "    \"\"\"\n",
        "    Convert flow into middlebury color code image\n",
        "    :param flow: optical flow map\n",
        "    :return: optical flow image in middlebury color\n",
        "    \"\"\"\n",
        "    u = flow[:, :, 0]\n",
        "    v = flow[:, :, 1]\n",
        "\n",
        "    maxu = -999.\n",
        "    maxv = -999.\n",
        "    minu = 999.\n",
        "    minv = 999.\n",
        "\n",
        "    idxUnknow = (abs(u) > UNKNOWN_FLOW_THRESH) | (abs(v) > UNKNOWN_FLOW_THRESH)\n",
        "    u[idxUnknow] = 0\n",
        "    v[idxUnknow] = 0\n",
        "\n",
        "    maxu = max(maxu, np.max(u))\n",
        "    minu = min(minu, np.min(u))\n",
        "\n",
        "    maxv = max(maxv, np.max(v))\n",
        "    minv = min(minv, np.min(v))\n",
        "\n",
        "    rad = np.sqrt(u ** 2 + v ** 2)\n",
        "    maxrad = max(-1, np.max(rad))\n",
        "\n",
        "    print (\"max flow: %.4f\\nflow range:\\nu = %.3f .. %.3f\\nv = %.3f .. %.3f\" % (maxrad, minu,maxu, minv, maxv))\n",
        "\n",
        "    u = u/(maxrad + np.finfo(float).eps)\n",
        "    v = v/(maxrad + np.finfo(float).eps)\n",
        "\n",
        "    img = compute_color(u, v)\n",
        "\n",
        "    idx = np.repeat(idxUnknow[:, :, np.newaxis], 3, axis=2)\n",
        "    img[idx] = 0\n",
        "\n",
        "    return np.uint8(img)\n",
        "\n",
        "\n",
        "def evaluate_flow(gt_flow, pred_flow):\n",
        "    \"\"\"\n",
        "    gt: ground-truth flow\n",
        "    pred: estimated flow\n",
        "    \"\"\"\n",
        "    average_pe = flow_error(gt_flow[:, :, 0], gt_flow[:, :, 1], pred_flow[:, :, 0], pred_flow[:, :, 1])\n",
        "    return average_pe\n",
        "\n",
        "\n",
        "def compute_color(u, v):\n",
        "    \"\"\"\n",
        "    compute optical flow color map\n",
        "    :param u: optical flow horizontal map\n",
        "    :param v: optical flow vertical map\n",
        "    :return: optical flow in color code\n",
        "    \"\"\"\n",
        "    [h, w] = u.shape\n",
        "    img = np.zeros([h, w, 3])\n",
        "    nanIdx = np.isnan(u) | np.isnan(v)\n",
        "    u[nanIdx] = 0\n",
        "    v[nanIdx] = 0\n",
        "\n",
        "    colorwheel = make_color_wheel()\n",
        "    ncols = np.size(colorwheel, 0)\n",
        "\n",
        "    rad = np.sqrt(u**2+v**2)\n",
        "\n",
        "    a = np.arctan2(-v, -u) / np.pi\n",
        "\n",
        "    fk = (a+1) / 2 * (ncols - 1) + 1\n",
        "\n",
        "    k0 = np.floor(fk).astype(int)\n",
        "\n",
        "    k1 = k0 + 1\n",
        "    k1[k1 == ncols+1] = 1\n",
        "    f = fk - k0\n",
        "\n",
        "    for i in range(0, np.size(colorwheel,1)):\n",
        "        tmp = colorwheel[:, i]\n",
        "        col0 = tmp[k0-1] / 255\n",
        "        col1 = tmp[k1-1] / 255\n",
        "        col = (1-f) * col0 + f * col1\n",
        "\n",
        "        idx = rad <= 1\n",
        "        col[idx] = 1-rad[idx]*(1-col[idx])\n",
        "        notidx = np.logical_not(idx)\n",
        "\n",
        "        col[notidx] *= 0.75\n",
        "        img[:, :, i] = np.uint8(np.floor(255 * col*(1-nanIdx)))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def make_color_wheel():\n",
        "    \"\"\"\n",
        "    Generate color wheel according Middlebury color code\n",
        "    :return: Color wheel\n",
        "    \"\"\"\n",
        "    RY = 15\n",
        "    YG = 6\n",
        "    GC = 4\n",
        "    CB = 11\n",
        "    BM = 13\n",
        "    MR = 6\n",
        "\n",
        "    ncols = RY + YG + GC + CB + BM + MR\n",
        "\n",
        "    colorwheel = np.zeros([ncols, 3])\n",
        "\n",
        "    col = 0\n",
        "\n",
        "    # RY\n",
        "    colorwheel[0:RY, 0] = 255\n",
        "    colorwheel[0:RY, 1] = np.transpose(np.floor(255*np.arange(0, RY) / RY))\n",
        "    col += RY\n",
        "\n",
        "    # YG\n",
        "    colorwheel[col:col+YG, 0] = 255 - np.transpose(np.floor(255*np.arange(0, YG) / YG))\n",
        "    colorwheel[col:col+YG, 1] = 255\n",
        "    col += YG\n",
        "\n",
        "    # GC\n",
        "    colorwheel[col:col+GC, 1] = 255\n",
        "    colorwheel[col:col+GC, 2] = np.transpose(np.floor(255*np.arange(0, GC) / GC))\n",
        "    col += GC\n",
        "\n",
        "    # CB\n",
        "    colorwheel[col:col+CB, 1] = 255 - np.transpose(np.floor(255*np.arange(0, CB) / CB))\n",
        "    colorwheel[col:col+CB, 2] = 255\n",
        "    col += CB\n",
        "\n",
        "    # BM\n",
        "    colorwheel[col:col+BM, 2] = 255\n",
        "    colorwheel[col:col+BM, 0] = np.transpose(np.floor(255*np.arange(0, BM) / BM))\n",
        "    col += + BM\n",
        "\n",
        "    # MR\n",
        "    colorwheel[col:col+MR, 2] = 255 - np.transpose(np.floor(255 * np.arange(0, MR) / MR))\n",
        "    colorwheel[col:col+MR, 0] = 255\n",
        "\n",
        "    return colorwheel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNbvxAcLu_5a"
      },
      "source": [
        "#Reading Train Dataframe\n",
        "df= pd.read_csv('/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Dataframes/alley1_train.csv')\n",
        "img1_list = df['img1'].to_list()\n",
        "img2_list = df['img2'].to_list()\n",
        "img3_list = df['img3'].to_list()\n",
        "flow_list = df['flow'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75s_GyLcvYi4"
      },
      "source": [
        "# Train inference function\n",
        "def train_inference():\n",
        "\n",
        "    imgpath = \"/final/final/\"\n",
        "    avgepe= 0.0\n",
        "    for i in range(len(df)):\n",
        "        img1 = tf.io.read_file(imgpath+img1_list[i])\n",
        "        img1 = tf.image.decode_png(img1, channels=3)\n",
        "        img1=tf.cast(img1,tf.float32)\n",
        "        img1=tf.reshape(img1,(1,436,1024,3))\n",
        "    \n",
        "        img2 = tf.io.read_file(imgpath+img2_list[i])\n",
        "        img2 = tf.image.decode_png(img2, channels=3)\n",
        "        img2=tf.reshape(img2,(1,436,1024,3))\n",
        "        img2=tf.cast(img2,tf.float32)\n",
        "\n",
        "        img3 = tf.io.read_file(imgpath+img3_list[i])\n",
        "        img3 = tf.image.decode_png(img3, channels=3)\n",
        "        img3=tf.reshape(img3,(1,436,1024,3))\n",
        "        img3=tf.cast(img3,tf.float32)\n",
        "\n",
        "        start = time.time()\n",
        "        flow_out=model(img1,img2, img3)\n",
        "        print ('Time taken for 1 Prediction {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "        test = flow_out['flow'][0].numpy()\n",
        "        test_visualize = visualize_flow_train(flow_out['flow'][0].numpy(),i)\n",
        "        gt_flow = readFlow(\"/flow/flow/\"+flow_list[i])\n",
        "        \n",
        "        evaluate = evaluate_flow(gt_flow,test)\n",
        "        print(\"Entry\",[i],\":\",evaluate)\n",
        "        avgepe+= evaluate\n",
        "    avg_epe= avgepe/len(df)\n",
        "    print(\"Training EPE:\", avg_epe)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dd17m7Ldwkod"
      },
      "source": [
        "train_inference()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIJzPIsSMxjZ"
      },
      "source": [
        "# Reading Test Dataframe\n",
        "df= pd.read_csv('/content/gdrive/My Drive/Thesis/Final_Training_Procedure/Dataframes/alley1_test.csv')\n",
        "img1_list = df['img1'].to_list()\n",
        "img2_list = df['img2'].to_list()\n",
        "img3_list = df['img3'].to_list()\n",
        "flow_list = df['flow'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FGG_AfbMxzo"
      },
      "source": [
        "# # Test inference function\n",
        "def test_inference():\n",
        "\n",
        "    imgpath = \"/final/final/\"\n",
        "    avgepe= 0.0\n",
        "    for i in range(len(df)):\n",
        "        img1 = tf.io.read_file(imgpath+img1_list[i])\n",
        "        img1 = tf.image.decode_png(img1, channels=3)\n",
        "        img1=tf.cast(img1,tf.float32)\n",
        "        img1=tf.reshape(img1,(1,436,1024,3))\n",
        "\n",
        "        img2 = tf.io.read_file(imgpath+img2_list[i])\n",
        "        img2 = tf.image.decode_png(img2, channels=3)\n",
        "        img2=tf.reshape(img2,(1,436,1024,3))\n",
        "        img2=tf.cast(img2,tf.float32)\n",
        "\n",
        "        img3 = tf.io.read_file(imgpath+img3_list[i])\n",
        "        img3 = tf.image.decode_png(img3, channels=3)\n",
        "        img3=tf.reshape(img3,(1,436,1024,3))\n",
        "        img3=tf.cast(img3,tf.float32)\n",
        "        \n",
        "        start = time.time()\n",
        "        flow_out=model(img1,img2, img3)\n",
        "        print ('Time taken for 1 Prediction {} sec\\n'.format(time.time() - start))\n",
        "        \n",
        "        test = flow_out['flow'][0].numpy()\n",
        "        test_visualize = visualize_flow_test(flow_out['flow'][0].numpy(),i)\n",
        "        gt_flow = readFlow(\"/flow/flow/\"+flow_list[i])\n",
        "        \n",
        "        evaluate = evaluate_flow(gt_flow,test)\n",
        "        print(\"Entry\",[i],\":\",evaluate)\n",
        "        avgepe+= evaluate\n",
        "    avg_epe= avgepe/len(df)\n",
        "    print(\"Testing EPE:\", avg_epe)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x3RZ7c4Mx91"
      },
      "source": [
        "test_inference()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQ41MmFBzvC"
      },
      "source": [
        " The Implementation for visualization and flow evalution compuation was taken as a reference from the GitHub Repository of Sam Pepose. The link to the repository is https://github.com/sampepose/flownet2-tf ."
      ]
    }
  ]
}